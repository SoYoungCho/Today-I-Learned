{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import trange\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import  datasets, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(train_batch_size, val_batch_size):\n",
    "    train_dataset = datasets.MNIST('./MNIST_Dataset', train = True, download = True, transform = transforms.ToTensor())\n",
    "    validation_dataset = datasets.MNIST(\"./MNIST_Dataset\", train = False, download = True, transform = transforms.ToTensor())\n",
    "    \n",
    "    train_loader = DataLoader(dataset = train_dataset, batch_size = train_batch_size, shuffle = True)\n",
    "    validation_loader = DataLoader(dataset = validation_dataset, batch_size = val_batch_size, shuffle = True)\n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_classifier, self).__init__()\n",
    "        #self.n_neuron = n_neuron\n",
    "        self.classifier = nn.Sequiential(\n",
    "            nn.Linear(28*28, 50),\n",
    "            nn.Dropout(0.2)\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Dropout(0.2)\n",
    "            nn.Linear(50, 10),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기서부터 다시. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_neuron_list = [10, 20, 30]\n",
    "loss_mat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #for idx, n_neuron in enum(n_neuron_list):\n",
    "    model = MLP_classifier(n_neuron = 10)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "    loss_mat.append(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
