#### Non-linear Decision Boundary

* linear 쌓아봤자 non-linear 만들 수 X
linear 조합하여 non-linear decision boundary 만들 수.
how?  layer 쌓아가면서.

* hidden layer 2개만 가지고 모든 function 구현 가능하다는 것은 이미 1900년대 증명되었다.
그럼에도 불구하고 여러 개 사용하는 이유는 ? -> 최적화 문제.

### Pytorch

: 딥러닝 프레임워크.
**torch.tensor** : numpy의 ndarray + GPU 얹은 것이라고 이해하면 됨.

	###Device Setting
	if torch.cuda.is_available():
		device = torch.device('cuda') #gpu
	else:
		device = torch.device('cpu')

* CPU 텐서와 GPU 텐서는 서로 연산을 못 함.
만일 모델은 gpu인데 텐서는 cpu면 연산 못함.
그래서 어디 device에 넣어줄 지도 중요. 모든 사람들이 돌릴 수 있도록 (유무 관계 없이) 세팅해주는 것.

import 할 때 numpy .. 등등 이랑
import 파이토치 관련이면 한줄 띄고 쓰는게 일반적.

데이터를 만들고 matplotlib에서 플롯팅하려면  cpu로 옮겨야
gpu에서 cpu로 옮기는 이런 코드 - 최소화 하는 것이 좋다 (cost가 큼)

import torch.nn as nn <- 모든 뉴럴 네트워크 다 가지고 있음.

	class LinearRegression(nn.Module):
		def __init__(self):
		..

이전에 z노드로 하나하나 다 만들던거

	model = LinearRegression()
	model.to(device) 이거면 다 해결! So EASY!

**hyper parameter** : epochs, lr,, 우리가 정해주어야 하는 것.

**optimizer.zero_grad()** : 에폭 돌릴 때 마다 grad 초기화.
grad 남아있으면 안 됨.

**state_dict()** : 에폭마다 / 하루마다 이런 기간 단위로 러닝된 과정 저장. (웨이트 이런거.) 오버피팅 된다 싶으면 돌릴 수도 있고.

**data leakage** : 에폭 돌릴 때마다 ram이 조금씩 찬다? 그러면
garbage collector나 malloc free 이런거에 신경 써줘야 함.
