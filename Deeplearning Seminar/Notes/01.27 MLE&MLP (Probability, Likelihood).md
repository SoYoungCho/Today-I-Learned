
# 2. MLE & MAP

## Probability VS Likelihood

데이터를 충분히 많이 뽑으면 Normal Distribution 따르게 된다.

예) 쥐의 몸무게 관련
$N = (\mu$ = 32 , $\sigma^{2}$ = 6.25) 정규분포 따르는 모델이 있을 때 

### likelihood

 (관심 있는 분포 | **data**)
쥐 한 마리를 뽑았을 때, 어떤 distribution에서 나올 확률이 클까?
즉, 뽑은 data가 **어떤 dist에서 나올지의 그 확률.** 내가 가지고 있는 data set이 어떤 모델을 가정했을 때, 그 모델에서 나올 확률.  (dist 모델)
 
 ### probability
 
 (관심 있는 데이터 확률 | **distribution**)
 이 분포에서 내가 관심 있는 무게가 나올 확률. 
 이미 dist를 가지고 있음

즉,
(probability)

내가 가진 모델에서 어떤 데이터가 나올 확률 

가진 것 : 모델
궁금한 것 : 데이터가 나올 확률

**vs**

(likelihood)
내가 가지고 있는 데이터가 어떤 모델(분포)에서 나올(뽑힐) 확률 

가진 것 : 데이터
궁금한 것  : 데이터에 대한 모델 분포

말장난 같겠지만 분명 다르다.

---

### Linear Regression 에서의 MLE

이제 이 likelihood를 가지고 어떻게 MLE 방법을 쓸 수 있을지 생각해보자.

ex ) 쥐 데이터를 얻었을 때, 모델을 여러 개 만들 수 있음. Normal dist라고 가정하면, 이에 대한 $\mu$, $\sigma$ 파라미터를 찾는 것이 목표.

이 데이터셋이 어떤 분포에서 나올 확률이 클까? -> MLE (maximum likelihood estimation)

std를 fix, mean을 와따리 가따리 한 모델 여러 개가 있다면
-> 가지고 있는 실제 data set의 mean을
그 모델 분포의 mean이라고 가정하는 것이
 전체 확률(데이터셋이 해당 모델에서 나올 확률)은 가장 크게 나옴 = 이것이 mean에 해당하는 MLE. std도 마찬가지.

---
$y = \theta_{1}x_{1} + \theta_{0}$ 모델이 있다면

theta에 따라 수많은 모델이 만들어짐.
우리가 가진 data set에 대해 어떤 모델(hypothesis)의 확률이 가장 높을지의 theta 값들을 뽑는 것.

= 지금까지 했던 linear regression도 이렇게 해서 MLE가 되는 것이라고 이해할 수 있다.

---

즉, Probability = P( $data$ | $dist$ )
Likelihood = P( $dist$ | $data$ )
그런데 이 **Prob 와 Likelihood 를 구하는 식은 동일**하다.

why?

(1) Probability 구할 때

dist의 $\mu$ 와 $\sigma$ 고정시켜 놓고
P($x$|$\mu$,$\sigma$) 구하기 위해선 -> 적분. x값의 확률을 구할 땐 적분.

동일하게,
(2) Likelihood 구할 때

데이터 x가 $dist_{1}$에서 나올 확률은 $\mu$ 와 $\sigma$을 갖는 이 $dist_{1}$에 x값을 넣는 것이 됨. 따라서 동일 (조금 헷갈릴 수 있으니 주의)

**$\mu$의  Likelihood 구하기**

**(i) 데이터가 1개인 경우**

$y(\mu$ = 28, $\sigma$ = 2| $x$ = 32 ) = 0.03
$y(\mu$ = 30, $\sigma$ = 2| $x$ = 32 ) = 0.12 

*(-> $\mu$ = 30, $\sigma$ = 2인 dist에서 나왔을 확률이 0.12라는 것.)*

이런식으로 다양하게 $\mu$을 바꿔가며 dist를 그렸을 때  어디서 나왔을 확률이 가장 높을까? -> Likelihood

Likelihood를 Maximum으로 갖는 $\mu$를 구하는 것.

**(ii) 데이터가 여러 개인 경우**

iid (Independent identically distributed)
: P(A와 B의 교집합) = P(A)P(B)

독립이라는 가정을 하기에
모든 데이터 $x_{1}$ ~ $x_{n}$까지의 해당 파라미터 (예) $\mu$ = 30, $\sigma$ = 2)에서의 likelihood를 곱해주면 된다. 모든 데이터 반영.

따라서 하나의 데이터에서의 likelihood가 높다고 전체 데이터셋의 likelihood가 높다고 보장할 수 없다.

**$\sigma$의 경우** 도 위와 마찬가지이다.
(데이터셋 전체에 대해 구할 경우 각 각 구해 곱하는 것과 동일)

---
### MLE를 Normal Distribution에 적용하기
#### 데이터 $x_{1}$ ~ $x_{n}$의 MLE가 되는 $\mu$와 $\sigma$구하는 방법 증명

**Point 1!** 
데이터셋에 대해 likelihood가 최대가 되는 **최적의 $\mu$ (혹은 $\sigma$)를 구한다는 것**

= 모든 데이터들을 반영한 최적의 모델에서 **가장 높은 지점**이 될 때의 $\mu$(혹은 $\sigma$)를 구하는 것

=  모든 데이터들을 반영한 최적의 모델에서 **기울기 = 0**이 되는 $\mu$(혹은 $\sigma$)를 구하는 것

**Point 2!** : 곱 -> 합으로 바꿔주기 위해 log를 사용한다.
log를 사용하면 곱 -> 합으로 바꿔주어 각 각 미적분이 가능해짐.

손으로 쓴 것 참조.

## 예제) 파라미터의 MLE 구하기

사진

$f(X_{i} | \theta)$ : 어떤 theta를 가정했을 때 데이터가 뽑힐 확률.

잠깐! 이건 prob에 대한 표현 아닌가?

그렇게 생각할 수도 있지만, 
likelihood: 내 데이터가 어떤 dist 가정하고 거기서 뽑힌 확률. 이렇게 써줄 수도 있음.

가진 것 : 데이터
궁금한 것  : 데이터에 대한 모델 분포 -> 이 분포를 가정할 수 있다는 말임.

풀이과정 사진

---


---
### MLE vs MAP 복습하기
prior prob까지 접목을 했는지가 제일 큰 차이.
prior prob 유무. 사전지식의 유무

uniform distribution에서 한다고 가정하면 MAP와 MLE와 동일.
(연속균등분포)

MLE : 그냥 막 동전을 던져보는 것
MAP : 동전이 휜 만큼 prior prob 주어 던지는 것 

1. 올바른 prior prob 주는 경우 : 다 잘 수렴하게 된다.
올바른 prior prob를 주어 강조하면 더 빠르게 수렴.
즉, 적당한 prior prob 를 주면 더 빠르고 정확하게 수렴한다. (DL, ML 마찬가지)

2.  잘못된 prior prob를 주는 경우 : 더 느리고 정확도도 떨어짐.
잘못된 prior prob만큼 더 동전을 던져야 함.
만일 prior prob를 더 강조하는 경우 (더 크면서 잘못된 prior prob)
정확도도 더 느리고 속도도 훨씬 느림.

argmax : theta를 최대로 하는 것

prior prob를 weight라고 이야기하는 개념도 있다. (많이 나오는 만큼 weight 준다는 의미.)

