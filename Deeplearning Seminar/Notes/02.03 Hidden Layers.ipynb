{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with 2 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선이 가장 많이 필요한 도형 --> 원.  \n",
    "뉴런의 개수를 늘려서 한번 decision boundary 만드는 것 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이어에서 뉴런의 개수는 선형인 선분의 개수.\n",
    "\n",
    "첫 번째 레이어에서 2개의 뉴런을 준다? 2개의 선형 그래프.  \n",
    "두 번째 레이어에서는 뉴런들을 어떻게 비선형으로 조합할지.\n",
    "\n",
    "* 참고! feature activation map 이라는 게 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Batch Size에 따른 Learning Result  \n",
    "\n",
    "-> 데이터 전체를 이용할 경우 데이터의 1프로를 배치 사이즈로 하는 것과 성능 (loss 감소) 차이가 많이 없었다.  \n",
    "    왜? 에폭별 데이터 전체를 다 이용하기 때문에 에폭이 달라져도 차이가 많이 없어서 그런듯."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hidden Layers\n",
    "\n",
    "#### 가운데 동그라미 부분에 대한 decision boundary를 긋는 예시가 있다.\n",
    "\n",
    "첫 번째 레이어에서 선분을 막 긋는데, 다 잘하진 않음. 잘 긋는 애들한테는 weight를 크게, 아니면 작게 준다.\n",
    "\n",
    "* 뉴런을 많이 사용하면 (노드를 많이) 성능이 좋을까?\n",
    "\n",
    "NO! 실험해보니 뉴런이 많아진다고 성능이 항상 좋아지는 것은 아니다.  \n",
    "\n",
    "비유 ) 개미들에서도 늘 일정 비율만 일을 하고 나머지는 배짱이처럼 핑핑 논다.\n",
    "이 비율은 항상 유지되는 것은 자연이 신비.. (?)\n",
    "\n",
    "하나의 뉴런에 x1을 넣어 y를 만든다 ? 이 뉴런은 binary classify만 잘하면 된다.  \n",
    "즉, 각 뉴런은 다음 레이어에서 결정을 잘하도록 도와준다는 것!  \n",
    "\n",
    "아 다르고 어 다를 수 있는데, 그래서 각 뉴런의 목적은 binary classify를 잘한다기 보단, 보조를 도와준다는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias\n",
    "bias : 뉴런이 얼마나 activation이 잘 되게 할지.  \n",
    "\n",
    "$y = sigmoid ( theta1 * x1 + theta2 * x2 + bias)$   \n",
    "\n",
    "따라서 theta1 * x1 + theta2 가 같더라도 bias가 커지면 0~1 중 1에 가까운 결과를 낸다.\n",
    "\n",
    "같은 맥락으로 (!) weight를 조절한다는 것은 각 선분들을 와따리 가따리 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 참고! Network Pruning / Quantization\n",
    "\n",
    "네트워크 안 weight bias를 다 돌리고 히스토그램을 그려봐서 일부는 사용이 안되면, 일 안하는 쓸 데 없는 네트워크는 가지 치면\n",
    "성능이 오를 것이다.   \n",
    "(대신 일정을 기준으로 하는 것이 아니라 전체 분포를 다 고려해야 할 것) 전부 다 반영이 되면 더 늘려고 될 것.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 레이어 : 뉴런들이 선형인 선분을 긋는다.  \n",
    "두 번째 레이어 : 첫 번째 뉴런들의 선분들로 비선형 바운더리  \n",
    "세 번째 레이어 : 두 번째 비선형 바운더리들을 이용하여 최종적인 비선형 바운더리 만든 것.  \n",
    "\n",
    "위에서 말했듯, 뉴런이 많아진다고 성능이 항상 좋아지는 것은 아니다!  \n",
    "왜일까? local optimum에 빠져서 global optimum 에 가지 못한 것으로 보임. (특히 learning rate이 작은 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만일,   \n",
    "\n",
    "**2 -> 16 -> 10 -> 2**  \n",
    "**vs**  \n",
    "**2-> 10 -> 16 -> 2**  \n",
    "\n",
    "앞에서 충분히 좋은 선분을 긋지 못한다면 뒤에 갈수록 망할 수 밖에 없다. (첫 단추를 잘못 끼운 것!!)\n",
    "\n",
    "첫 번째 레이어에서 좋은 선분들이 많으면 두 번째 레이어에서 더 좋은 성능 보일 것.\n",
    "\n",
    "뉴런의 개수가 똑같더라도 앞에서 잘 못하면 뒤에서도 잘 못할 가능성이 높다.\n",
    "따라서 대부분 네트워크들은 앞 부분에서 연산량이 큰 경우가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 결론 : 스택을 무조건 쌓는다고 좋은 것은 아니다.\n",
    "스택을 쌓을지, 같은 레이어에서 뉴런 개수를 늘릴지 이런 고민도 따라서 필요한 것.\n",
    "\n",
    "(1레이어에서 10개 쓰는 것 > 1레이어 5개 뉴런, 2레이어 5개 뉴런). 이렇게 될 수."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unrelated Features (random noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = x1 + x2\n",
    "\n",
    "i) 이런 y에 , y와 전혀 연관 없는 랜덤한 값 normal distrubution 으로 x3를 넣으면? (random noise)\n",
    "\n",
    "쓸모 없는 디멘션이 많아질 수록 테스트 시 성능은 떨어짐.\n",
    "-> 노이즈가 됨. 작은 값이더라도 prediction에 영향을 주어 test accurcy가 떨어질 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) 쓸 모 없는 데이터를 넣더라도 전부 다 0로 통일 / 1로 통일하면 위 noise 성 feature보다 예측시 영향이 덜하다.\n",
    "\n",
    "예를 들어 MNIST에서 7 숫자면 7 밖의 픽셀 피처는 거의 다 0이다. \n",
    "그런데 성능이 거의 떨어지지 않기 때문에 상관 없당!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
