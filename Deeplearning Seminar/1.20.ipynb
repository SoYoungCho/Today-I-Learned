{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저번 시간 복습\n",
    "\n",
    "$ y = \\theta_{1} x_{1} + \\theta_{0} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식에서 $\\theta_{1} 와 \\theta_{0} $의 업데이트 식 차이는 \n",
    "\n",
    "$\\theta_{1} = \\theta_{1} - \\alpha * (-2x^{(i)})(y^{(i)} - \\theta_{1}x^{(i)} - b)$ <br>\n",
    "$\\theta_{0} = \\theta_{0} - \\alpha * (-2)(y^{(i)} - \\theta_{0}x^{(i)} - b)$\n",
    "\n",
    "$x^{(i)}$가 곱해지는지의  유무였다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{1} 와 \\theta_{0}$의 cost function이 비슷하면 3차원으로 이 cost function을 그렸을 때 엎어놓은 밥그릇 모양이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost function을 contour plot으로 그리면 똥그랗게 예쁜 모양으로 그려진다. 따라서 lr를 잘 정해주면 방황하지 않고 최적의 러닝을 하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처가 여러 개가 되는 경우 (x가 여러 개)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ = 1,2,3,4,5 (공부시간) <br>\n",
    "$y$ = 2,3,4,5,6 (시험성적)\n",
    "\n",
    "이런 데이터에서 $x 말고 x1, x2$ 등 다양한 피처가 추가되는 경우에 대해 생각해보자. <br>\n",
    "(이 때,여기 다른 변수 $x1, x2$들은 linear 하다는 보장이 있어야한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 만약 이미지라면 피처의 개수는 H X W , 즉 이미지 가로 세로 픽셀 개수를 곱한 것과 같이 어마어마하게 많게 된다. -> 이런 경우 multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = \\theta_{2}x_{2} + \\theta_{1}x_{1} + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식에서 $x2와 x1$가 각 각 독립적으로 $y$와 relationship 있어야.\n",
    "\n",
    "즉 $x2와 x1$은 서로 상관관계가 없어야. = correlation이 없어야. 서로 독립이라는 가정. independant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covariance 와 correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correlation\n",
    "\n",
    "-1 ~ 1로 표현. 1에 가까운 경우 하나가 커지면 다른 하나도 커지고, -1에 가까운 경우 하나가 커지면 다른 하나는 반대로 작아짐.\n",
    "\n",
    "0에 가까울수록 상관관계 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.corrcoef(x2,x1) 이렇게 쓰고, 대각선에는 자기 자신이기에 1이 온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 개의 피처 $x_{1} .. x_{n}$ 사이 상관관계 있는 것은 빼야한다. **상관관계가 있다면 linear regression을 망칠 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저번에 배운 것 처럼 \n",
    "\n",
    "\n",
    "$y = \\theta_{2}x_{2} + \\theta_{1}x_{1} + b$\n",
    "\n",
    "$x_{2}, x_{1}$는 각 각 사이즈의 $\\mu$ 와 $\\sigma$ 맞춰주어야 한다. ($\\theta_{i}$ learning에 미치는 영향이 너무 direct 하기 때문.)\n",
    "\n",
    "반면 $bias$는 $\\mu$ 와 $\\sigma$와 데이터 분포의 영향을 받지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 원하는 학습 결과를 위해 $x_{i}$의 $\\mu$ 와 $\\sigma$를 보고 정규화 해주고, correlation도 봐주자! <br>\n",
    "피처들 간의 상관관계를 보고, 상관관계가 있다면 둘 다 넣지 말고 조금 더 target과 유사도가 높은 $x_{i}$를 남긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만일, $\\theta$가 3개인데 feature scaling을 안해주면?\n",
    "\n",
    "cost function을 그렸을 때 V, U, ㅡ 이렇게 각 각 생길 위험이 있다.\n",
    "V는 발산 가능 ㅡ는 학습이 안될 수도.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
